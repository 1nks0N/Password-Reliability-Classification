{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulate research Questions\n",
    "**1.** Load the dataset and check the dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = data['strength'].value_counts()\n",
    "plt.bar(value_counts.index, value_counts.values)\n",
    "plt.xlabel('Strength')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data structure is very simple, the data labels are only two columns and there are no null values.\n",
    "\n",
    "In this dataset, the highest rating of password strength is 2 and the lowest rating is 0. The outliers in the dataset can be found by finding the number of columns 'strength' that are greater than 2 and less than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = any((data['strength'] > 2) | (data['strength'] < 0))\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no nulls or outliers in the dataset, the data cleaning process can be skipped.\n",
    "\n",
    "In this worksheet, the research objective is to determine the strength of the password, we need to find the features in the password that can affect the strength, in this step, these features can be obtained by splitting the information in the password part of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse password features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digits_number(password: str):\n",
    "    return sum(c.isdigit() for c in password)\n",
    "\n",
    "def lower_letters(password: str):\n",
    "    return sum(c.islower() for c in password)\n",
    "\n",
    "def upper_letters(password: str):\n",
    "    return sum(c.isupper() for c in password)\n",
    "\n",
    "def special_chars(password: str):\n",
    "    return sum(not c.isalnum() for c in password)\n",
    "\n",
    "def password_length(password: str):\n",
    "    return len(password)\n",
    "\n",
    "data_features = data.copy()\n",
    "\n",
    "data_features = data_features.password.agg([password_length, digits_number, lower_letters, upper_letters, special_chars])\n",
    "data_features['level'] = data['strength']\n",
    "\n",
    "print(data_features.shape)\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_features.to_csv('features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_features.drop('level', axis=1)\n",
    "target = data_features['level']\n",
    "\n",
    "def score_model(features, target, model, scoring='f1_macro'):\n",
    "    scores = cross_val_score(model, features, target, cv=5, scoring=scoring)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_confusion_matrix(features, target, model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.4, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    model_name = model.__class__.__name__\n",
    "\n",
    "    sp = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    sp.set_title(f'Confusion matrix for {model_name}')\n",
    "    sp.set(xlabel='Predicted label', ylabel='True label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score_model(features, target, LogisticRegression(max_iter=500))\n",
    "print(f'Logistic Regression score: {score}')\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=500)\n",
    "logreg_model.fit(features, target)\n",
    "\n",
    "coefficients = logreg_model.coef_[0]\n",
    "\n",
    "feature_importance = zip(features.columns, coefficients)\n",
    "feature_importance = sorted(feature_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feature, coef in feature_importance:\n",
    "    print(f'Feature: {feature} - Coef: {coef}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(logreg_model.coef_[0])), logreg_model.coef_[0])\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coef')\n",
    "plt.title('Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_confusion_matrix(features, target, LogisticRegression(max_iter=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score_model(features, target, MLPClassifier(hidden_layer_sizes=(100,), max_iter=500))\n",
    "print(f'MLP Classifier score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_confusion_matrix(features, target, MLPClassifier(hidden_layer_sizes=(100,), max_iter=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score_model(features, target, SGDClassifier())\n",
    "print(f'SGDClassifier score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_confusion_matrix(features, target, SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score_model(features, target, RandomForestClassifier())\n",
    "print(f'RandomForestClassifier score: = {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_confusion_matrix(features, target, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_features, hue='level', palette='bright')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_strings(password: str):\n",
    "    return max(password.count(c) for c in password)\n",
    "\n",
    "data_after = pd.DataFrame({'duplicate': data['password'].apply(find_duplicate_strings)})\n",
    "data_after = pd.concat([data_features, data_after], axis=1)\n",
    "\n",
    "data_after.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
